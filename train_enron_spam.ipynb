{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:24:14.842676Z",
     "start_time": "2018-11-12T21:24:14.808051Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:09:14.715374Z",
     "start_time": "2018-11-12T21:09:14.688814Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_enron_data(path):\n",
    "    \"\"\"Load Enron email data from path into a file.\"\"\"\n",
    "    for filename in os.listdir(path):\n",
    "        row = {\n",
    "            'filename': filename,\n",
    "            'content': open(os.path.join(path, filename), 'r', encoding='latin1').read()\n",
    "        }\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:11:03.452619Z",
     "start_time": "2018-11-12T21:11:03.331434Z"
    }
   },
   "outputs": [],
   "source": [
    "spam_df = pd.DataFrame(load_enron_data('data/enron1/spam/'))\n",
    "spam_df['is_spam'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:11:03.751790Z",
     "start_time": "2018-11-12T21:11:03.485429Z"
    }
   },
   "outputs": [],
   "source": [
    "ham_df = pd.DataFrame(load_enron_data('data/enron1/ham'))\n",
    "ham_df['is_spam'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:14:27.102511Z",
     "start_time": "2018-11-12T21:14:27.062811Z"
    }
   },
   "outputs": [],
   "source": [
    "email_df = pd.concat([spam_df, ham_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline of data: taking a Python object, saving as a pickle, then can be used elsewhere (websites, etc.)\n",
    "Pipeline class from sklearn can train model on data and can make predictions on new data. Pickle contains whatever the model learns and uses that (pickling can be done on many differrent Python objects). Pipelines can not be fully built on accuracy, as that metric does not really focus on the business case be able to function in the real world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:18:54.640567Z",
     "start_time": "2018-11-12T21:18:53.927480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...e,\n",
       "        vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(stop_words='english')\n",
    "model = MultinomialNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(email_df['content'], email_df['is_spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:22:00.581824Z",
     "start_time": "2018-11-12T21:22:00.545284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05751643, 0.94248357],\n",
       "       [0.97106817, 0.02893183]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba([\n",
    "    'cheap viagra',         # Spam\n",
    "    'meeting lunch energy'  # Not spam\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T21:24:27.223071Z",
     "start_time": "2018-11-12T21:24:26.976164Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('spam_model.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
